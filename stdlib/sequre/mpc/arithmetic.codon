from numpy.create import _extract_shape
from sequre.constants import MPC_RING_SIZE, MPC_FIELD_SIZE

from stats import MPCStats
from randomness import MPCRandomness
from comms import MPCComms


class MPCArithmetic[TP]:
    pid: int
    
    stats: MPCStats
    randomness: MPCRandomness
    comms: MPCComms[TP]
    
    def __init__(self, comms: MPCComms[TP]):
        self.pid = comms.pid
        self.stats = comms.stats
        self.randomness = comms.randomness
        self.comms = comms

        self.reset_stats()
    
    def reset_stats(self):
        self.stats.reset_arithmetic_stats()
    
    def print_stats(self, file_stream = None):
        self.stats.print_arithmetic_stats(file_stream)
    
    def ring_to_field(self, target):
        return self.__switch_modulus(target, MPC_RING_SIZE, MPC_FIELD_SIZE)
    
    def field_to_ring(self, target):
        return self.__switch_modulus(target, MPC_FIELD_SIZE, MPC_RING_SIZE)

    def add_public(self, x, a, modulus):
        if self.pid == 1:
            return x.add_mod(a, modulus)
        return x
    
    def multiply(self, a, b, modulus):
        x_1_r, r_1 = self.__beaver_partition(a, modulus)
        x_2_r, r_2 = self.__beaver_partition(b, modulus)
        
        c = self.__beaver_mul(x_1_r, r_1, x_2_r, r_2, modulus)
        c = self.__beaver_reconstruct(c, modulus)
        
        return c

    def multiply_matmul(self, a, b, modulus):
        x_1_r, r_1 = self.__beaver_partition(a, modulus)
        x_2_r, r_2 = self.__beaver_partition(b, modulus)

        c = self.__beaver_matmul(x_1_r, r_1, x_2_r, r_2, modulus)
        c = self.__beaver_reconstruct(c, modulus)
        
        return c
    
    def beaver_inner_prod(self, ar, am, modulus):
        # TODO: #55 This method might be redundant with __beaver_dot_prod and not needed
        ab = am.mul_mod(am, modulus) if self.pid == 0 else ar.mul_mod(am, modulus).lsh_mod(1, modulus)
        if self.pid == 1:
            ab = ab.add_mod(ar.mul_mod(ar))

        cum_sum = type(modulus)(0)
        for e in ab: cum_sum = cum_sum.add_mod(e, modulus)

        return cum_sum
    
    def inner_prod(self, a, modulus):
        ar, am = self.__beaver_partition(a, modulus)
        n = len(a)

        c = list[type(modulus)](n)
        for i in range(n): c.append(self.beaver_inner_prod(ar[i], am[i], modulus))

        return self.__beaver_reconstruct(c, modulus)
    
    def __beaver_partition_mat_bulk(self, x, modulus):
        # TODO: #55 Deprecate this method
        # TODO: #55 Do this in parallel
        x_r_bulk, r_bulk = self.__beaver_partition(x.flatten_numpy(), modulus)
        x_r = x_r_bulk.reshape_numpy(_extract_shape(x))
        r = r_bulk.reshape_numpy(_extract_shape(x))
        return x_r, r
    
    def __beaver_reconstruct_mat_bulk(self, x, modulus):
        # TODO: #55 Deprecate this method
        # TODO: #55 Do this in parallel
        return self.__beaver_reconstruct(x.flatten_numpy(), modulus).reshape_numpy(_extract_shape(x))

    def multiply_bulk(self, a, b, modulus):
        # TODO: #55 Deprecate this method
        # TODO: #16 Vectorize this method. Make it parallel by having a and b as ndarrays.
        nmat = len(a)

        ar, am = self.__beaver_partition_mat_bulk(a, modulus)
        br, bm = self.__beaver_partition_mat_bulk(b, modulus)

        c = [self.__beaver_mul(ar[k], am[k], br[k], bm[k], modulus)
             for k in range(nmat)]
        
        return self.__beaver_reconstruct_mat_bulk(c, modulus)
    
    def multiply_mat_bulk(self, a, b, modulus):
        # TODO: #55 Deprecate this method
        # TODO: #16 Vectorize/parallelize this method. Make it parallel by having a and b as ndarrays.
        nmat = len(a)

        ar, am = self.__beaver_partition_mat_bulk(a, modulus)
        br, bm = self.__beaver_partition_mat_bulk(b, modulus)

        c = [self.__beaver_matmul(ar[k], am[k], br[k], bm[k], modulus)
             for k in range(nmat)]
            
        return self.__beaver_reconstruct_mat_bulk(c, modulus)
    
    def beaver_inner_prod_pair(self, ar, am, br, bm, modulus):
        # TODO: #55 Deprecate this method
        ab = type(modulus)(0)
        
        for i in range(len(ar)):
            if self.pid == 0:
                ab = am[i].mul_mod(bm[i], modulus).mul_add(ab, modulus)
            else:
                ab = ar[i].mul_mod(bm[i], modulus).mul_add(ab, modulus)
                ab = br[i].mul_mod(am[i], modulus).mul_add(ab, modulus)
                if self.pid == 1: ab = ar[i].mul_mod(br[i], modulus).mul_add(ab, modulus)

        return ab
    
    def validate_partitions(self, x, x_r, r, modulus, message = ""):
        if self.pid:
            self.comms.send_as_jar(r, 0)
            partition_share = (x_r if self.pid == 1 else x_r.zeros()).add_mod(r, modulus)
            partition_reveal = self.comms.reveal(partition_share, modulus)
            share_reveal = self.comms.reveal(x, modulus)
            assert partition_reveal == share_reveal, f"{message}:\n\tPartition reveal: {partition_reveal}\n\tShare reveal: {share_reveal}"
        else:
            r_sum = r.zeros()
            for i in range(1, self.comms.number_of_parties):
                r_i = self.comms.receive_as_jar(i, T=type(r))
                r_sum.add_mod(r_i, modulus)
            assert r == r_sum, "Invalid partitions at CP0"
    
    def __beaver_partition(self, value, modulus):
        self.stats.partitions_count += 1

        if self.pid == 0:
            r = value.zeros()
            
            for i in range(1, self.comms.number_of_parties):
                with self.randomness.seed_switch(i):
                    r = r.add_mod(value.rand(modulus, "uniform"), modulus)

            return value.zeros(), r
        else:
            with self.randomness.seed_switch(0):
                r = value.rand(modulus, "uniform")
            
            x_r = value.sub_mod(r, modulus)
            x_r = self.comms.reveal(x_r, modulus)

            return x_r, r

    def __beaver_reconstruct(self, value, modulus):
        self.stats.reconstructs_count += 1

        if self.pid == 0:
            mask = value.zeros()

            for i in range(2, self.comms.number_of_parties):
                with self.randomness.seed_switch(i):
                    mask = mask.add_mod(value.rand(modulus, "uniform"), modulus)

            r = value.sub_mod(mask, modulus)
            self.comms.send(r, 1)
            
            return r
        elif self.pid == 1:
            return value.add_mod(
                self.comms.receive(0, T=type(value)), modulus)
        else:
            with self.randomness.seed_switch(0):
                return value.add_mod(
                    value.rand(modulus, "uniform"), modulus)
    
    def __beaver_mul(self, x_r, r_1, y_r, r_2, modulus):
        if self.pid == 0:
            return r_1.mul_mod(r_2, modulus)

        xy = x_r.mul_mod(r_2, modulus)
        xy = r_1.mul_mod(y_r, modulus).add_mod(xy, modulus)
        
        if self.pid == 1: xy = x_r.mul_mod(y_r, modulus).add_mod(xy, modulus)

        return xy
    
    def __beaver_matmul(
            self, x_r, r_1, y_r, r_2, modulus):
        if self.pid == 0:
            return r_1.matmul_mod(r_2, modulus)

        xy = x_r.matmul_mod(r_2, modulus)
        xy = xy.add_mod(r_1.matmul_mod(y_r, modulus), modulus)
        if self.pid == 1:
            xy = xy.add_mod(x_r.matmul_mod(y_r, modulus), modulus)

        return xy
    
    def __beaver_dot_prod(self, x_r, r_1, y_r, r_2, axis, modulus):
        assert 0 <= axis < x_r.ndim, "MPC.arithmetic: invalid axis for dot product"
        xy = self.__beaver_mul(x_r, r_1, y_r, r_2, modulus)
        
        if not isinstance(xy, ByVal):
            xy = xy.transpose() if axis == 1 else xy
        
        cum_sum = xy[0].zeros()
        for e in xy: cum_sum = cum_sum.add_mod(e, modulus)

        return cum_sum
    
    def __switch_modulus(self, target, from_mod, to_mod):
        # TODO: Major error needs to be fixed here.
        # Method should return the valye: target + (from_mod - to_mod) * from_mod // target.
        return self.add_public(target, to_mod.sub_mod(from_mod, to_mod), to_mod)
